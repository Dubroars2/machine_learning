{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#придумаем 2 признака в переменную Х\n",
    "X = np.array( [\n",
    "    [1,1],\n",
    "    [1,2],\n",
    "    [2,2],\n",
    "    [3,4],\n",
    "    [5,6]  \n",
    "])\n",
    "\n",
    "#y = 2*x1+3*x2 + 4 - любая зависимость, нужно просто, чтобы правильно сформировать таргеты\n",
    "y = np.array([\n",
    "    9,\n",
    "    12,\n",
    "    14,\n",
    "    22,\n",
    "    32    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Наша линейная регрессия состоит из 2 признаков и 3-х параметров (2, 3, 4)\n",
    "#t1, t2, t3 = какие-то случайные числа\n",
    "\n",
    "t1, t2, t3 = random.random(), random.random(), random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Напишим ф-ю, которая делает предсказания для нашей линейной регрессии\n",
    "#Она на вход принимает Х и коэффициенты\n",
    "\n",
    "def lin_reg(x1, x2, t1, t2, t3):\n",
    "    return x1*t1 + x2*t2 + t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406432316643368"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg(X[0,0], X[0,1], t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задача подобрать оптимальные коэф t1, t2, t3\n",
    "#которые наилучшим образом описывают наши данные. т.е. с этими коэф наша ф-я потерь достигает миним (ф-я потерь это MSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Научиться эту ф-ю потерь считать. Научимся для одного примера считать\n",
    "def mse_one_example(x1, x2, t1, t2, t3, y):\n",
    "    return (lin_reg(x1, x2, t1, t2, t3)-y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.95323151931785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Для первого примера MSE\n",
    "mse_one_example(X[0,0], X[0,1], t1, t2, t3, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нам нужно посчитать МСЕ теперь для всей выборки\n",
    "#Передаем матрицу Х и у в ф-ю и коэф\n",
    "#Как будет работать. Посчитать МСЕ для всех примеров, сложить их и делить на кол-во примеров\n",
    "def mse(X, y, t1, t2, t3):\n",
    "    num_of_samples = len(y) #сколько записей в y\n",
    "    total_mse = 0\n",
    "    for i in range(num_of_samples): #пробегаемся по всем нашим примерам\n",
    "        total_mse += mse_one_example(X[i, 0], X[i, 1], t1,t2,t3, y[0])\n",
    "        # добавляем сюда МСЕ для одного примера. Это 0 признак для iитого объекта, потом 1 признак для iитого объекта\n",
    "        #коэф и правильный ответ для iитого примера\n",
    "        return   total_mse / num_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.99064630386357"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(X, y, t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Начнем делать градиентный спуск. Для этого нужно научиться получать производные по каждому из наших параметров.\n",
    "#Мы хотим оптимизировать - ф-ю потерь. У нас три параметра t1,t2,t3. Значит нам нужно вычислить 3 производные по этим параметрам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем ф-ю первой частной производной\n",
    "def der_mse_t1(X, y, t1, t2, t3):\n",
    "    num_of_samples = len(y) \n",
    "    total_mse_der = 0\n",
    "    for i in range(num_of_samples): \n",
    "        #Бежим по всем примерам\n",
    "        total_mse_der += (lin_reg(X[i, 0], X[i, 1], t1,t2,t3) - y[i] * X[i,0])\n",
    "        #складываем прогноз модели (lin_reg(X[i, 0], X[i, 1], t1,t2,t3) - правильный ответ  y[i] \n",
    "        #* на соответствующий признак этого набюлдения X[i,0]\n",
    "    return  2 *  total_mse_der / num_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем ф-ю второй частной производной. Это параметр при свободном частном члене \n",
    "def der_mse_t2(X, y, t1, t2, t3):\n",
    "    num_of_samples = len(y) \n",
    "    total_mse_der = 0\n",
    "    for i in range(num_of_samples): \n",
    "        #Бежим по всем примерам\n",
    "        total_mse_der += (lin_reg(X[i, 0], X[i, 1], t1,t2,t3) - y[i] * X[i,1])\n",
    "        #Разница только в том, что берем не первый признак, а второй X[i,1]\n",
    "    return  2 *  total_mse_der / num_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем последнюю частную производную. Это просто разница прогноза и правильного ответа \n",
    "\n",
    "def der_mse_t3(X, y, t1, t2, t3):\n",
    "    num_of_samples = len(y) \n",
    "    total_mse_der = 0\n",
    "    for i in range(num_of_samples): \n",
    "        #Бежим по всем примерам\n",
    "        total_mse_der += (lin_reg(X[i, 0], X[i, 1], t1,t2,t3) - y[i])\n",
    "        #Убираем умножение на X[i,1]) \n",
    "    return  2 *  total_mse_der / num_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.771716806694847"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der_mse_t3(X, y, t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Градиентный спуск - мы вычислили наши частные производные и дальше на их основе корректируем наш параметр "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt - производные \n",
    "#lr - шаг, леарнинг рейт\n",
    "#Запишем ф-ю правила обновления градиентного спуска\n",
    "def do_gradiend_update(t1, t2, t3, dt1, dt2, dt3, lr):\n",
    "    return (\n",
    "    t1 - lr * dt1,\n",
    "    t2 - lr * dt2,\n",
    "    t3 - lr * dt3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запишем правило \n",
    "def do_gradiend_step(X, y, t1, t2, t3, lr):\n",
    "      #Вычисляем наши частные производные \n",
    "    dt1 = der_mse_t1(X, y, t1, t2, t3)\n",
    "    dt2 = der_mse_t2(X, y, t1, t2, t3)\n",
    "    dt3 = der_mse_t3(X, y, t1, t2, t3)\n",
    "    \n",
    "    #Делаем градиентный апдейт \n",
    "    return do_gradiend_update(t1, t2, t3, dt1, dt2, dt3, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE UPDATE. \n",
      "T1: 1.8775826320686715, \n",
      "T2: 2.5546290944411014, \n",
      "T3: 0.512951071734067\n",
      "LOSS 3.2883409465491455\n",
      "\n",
      "GRADINTS. \n",
      "DT1: -84.63392665595563, \n",
      "DT2: -111.03392665595564, \n",
      "DT3: -10.233926655955633\n",
      "\n",
      "AFTER UPDATE. \n",
      "T1: 2.7239218986282276, \n",
      "T2: 3.664968361000658, \n",
      "T3: 0.6152903382936232\n",
      "LOSS 0.796659017141791\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE UPDATE. \\nT1: {}, \\nT2: {}, \\nT3: {}\".format(t1, t2, t3))\n",
    "print(\"LOSS {}\".format(mse(X,y,t1,t2,t3)))\n",
    "print(\"\")\n",
    "dt1 = der_mse_t1(X, y, t1, t2, t3)\n",
    "dt2 = der_mse_t2(X, y, t1, t2, t3)\n",
    "dt3 = der_mse_t3(X, y, t1, t2, t3)\n",
    "print(\"GRADINTS. \\nDT1: {}, \\nDT2: {}, \\nDT3: {}\".format(dt1, dt2, dt3))\n",
    "print(\"\")\n",
    "t1, t2, t3 = do_gradiend_update(t1, t2, t3, dt1, dt2, dt3, lr)         \n",
    "print(\"AFTER UPDATE. \\nT1: {}, \\nT2: {}, \\nT3: {}\".format(t1, t2, t3))\n",
    "print(\"LOSS {}\".format(mse(X,y,t1,t2,t3))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
